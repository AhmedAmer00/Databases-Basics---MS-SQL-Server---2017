{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepfake_video_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9UerjPh78QButhxoLjgjA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedAmer00/Databases-Basics---MS-SQL-Server---2017/blob/master/deepfake_video_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWw__MQq2DGk",
        "outputId": "63ee0096-b0a6-4b59-f17f-1eaffeab57e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deepfakes_video_classification'...\n",
            "remote: Enumerating objects: 154, done.\u001b[K\n",
            "remote: Counting objects: 100% (154/154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 154 (delta 81), reused 79 (delta 30), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (154/154), 2.62 MiB | 3.80 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AKASH2907/deepfakes_video_classification.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgnNUaF92XCq",
        "outputId": "d5c4b708-d496-4d4f-faee-bc5b57c6e612"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pc-qAHqTjpz",
        "outputId": "33373393-6b6e-455e-fde4-cf3c4b63f185"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_submission.csv  \u001b[0m\u001b[01;34mtest_videos\u001b[0m/  \u001b[01;34mtrain_sample_videos\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/deepfake-detection-challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab6n9qqT2uti",
        "outputId": "789f473f-21b8-42cc-ed1d-f1b2db71437c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/deepfake-detection-challenge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RgiUdtkq2jjL",
        "outputId": "1685d62e-0124-43b1-fb99-d5f3d4316f31"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/deepfake-detection-challenge'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwdc='/content/drive/MyDrive/deepfake-detection-challenge'"
      ],
      "metadata": {
        "id": "oO2r5QVWUt3L"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from os import makedirs\n",
        "from os.path import join, exists\n",
        "import glob\n",
        "\n",
        "training_videos_folder = [pwdc+\"/train_sample_videos\"]\n",
        "\n",
        "for folder in training_videos_folder:\n",
        "    videos_path = glob.glob(join(folder, \"*.mp4\"))\n",
        "    folder = folder.split(\"/\")[1]\n",
        "\n",
        "    print(folder)\n",
        "\n",
        "    counter = 0\n",
        "    for video_path in videos_path:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        vid = video_path.split(\"/\")[-1]\n",
        "        vid = vid.split(\".\")[0]\n",
        "        frameRate = cap.get(5)  # frame rate\n",
        "\n",
        "        if not exists(pwdc+\"/train_frames/\" + folder + \"/video_\" + str(int(counter))):\n",
        "            makedirs(pwdc+\"/train_frames/\" + folder + \"/video_\" + str(int(counter)))\n",
        "\n",
        "        while cap.isOpened():\n",
        "            frameId = cap.get(1)  # current frame number\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            filename = (\n",
        "                pwdc+\"/train_frames/\"\n",
        "                + folder\n",
        "                + \"/video_\"\n",
        "                + str(int(counter))\n",
        "                + \"/image_\"\n",
        "                + str(int(frameId) + 1)\n",
        "                + \".jpg\"\n",
        "            )\n",
        "            cv2.imwrite(filename, frame)\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        if counter % 100 == 0:\n",
        "            print(\"Number of videos done:\", counter)\n",
        "        counter += 1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogTrFMJW4dhY",
        "outputId": "7e5f62fa-6803-4582-88bf-1aa0ced7b10e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content\n",
            "Number of videos done: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install facenet-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0nzt7OJ6cl4",
        "outputId": "cf94fe73-7d8c-4235-fb8f-34890ad3d213"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting facenet-pytorch\n",
            "  Downloading facenet_pytorch-2.5.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (0.11.1+cu111)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (1.21.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from facenet-pytorch) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->facenet-pytorch) (3.0.4)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet-pytorch) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision->facenet-pytorch) (3.10.0.2)\n",
            "Installing collected packages: facenet-pytorch\n",
            "Successfully installed facenet-pytorch-2.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import MTCNN\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "from os import listdir, makedirs\n",
        "import glob\n",
        "from os.path import join, exists\n",
        "from skimage.io import imsave\n",
        "import imageio.core.util\n",
        "\n",
        "\n",
        "def ignore_warnings(*args, **kwargs):\n",
        "    pass\n",
        "\n",
        "\n",
        "imageio.core.util._precision_warn = ignore_warnings\n",
        "\n",
        "# Create face detector\n",
        "# If you want to change the default size of image saved from 160, you can\n",
        "# uncomment the second line and set the parameter accordingly.\n",
        "mtcnn = MTCNN(\n",
        "    margin=40,\n",
        "    select_largest=False,\n",
        "    post_process=False,\n",
        "    device=\"cuda:0\"\n",
        ")\n",
        "# mtcnn = MTCNN(margin=40, select_largest=False, post_process=False,\n",
        "# device='cuda:0', image_size=256)\n",
        "\n",
        "# Directory containing images respective to each video\n",
        "source_frames_folders = [\"../train_frames/0/\"]\n",
        "# Destination location where faces cropped out from images will be saved\n",
        "dest_faces_folder = \"../train_face/0/\"\n",
        "\n",
        "\n",
        "for i in source_frames_folders:\n",
        "    counter = 0\n",
        "    for j in listdir(i):\n",
        "        imgs = glob.glob(join(i, j, \"*.jpg\"))\n",
        "        if counter % 1000 == 0:\n",
        "            print(\"Number of videos done:\", counter)\n",
        "        if not exists(join(dest_faces_folder, j)):\n",
        "            makedirs(join(dest_faces_folder, j))\n",
        "        for k in imgs:\n",
        "            frame = cv2.imread(k)\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = Image.fromarray(frame)\n",
        "            face = mtcnn(frame)\n",
        "\n",
        "            try:\n",
        "                imsave(\n",
        "                    join(dest_faces_folder, j, k.split(\"/\")[-1]),\n",
        "                    face.permute(1, 2, 0).int().numpy(),\n",
        "                )\n",
        "            except AttributeError:\n",
        "                print(\"Image skipping\")\n",
        "        counter += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "WZg1H3cw4zP4",
        "outputId": "33749dd8-cc82-43b6-88fe-599c66fb7a84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d4a878a5c5a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource_frames_folders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"*.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../train_frames/0/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JyTvPc5MTUDD",
        "outputId": "7c3f5735-7906-4728-9d70-25c7d322d072"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}